{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook Title: National Data Buoy Center (NDBC) Realtime Data Download**\n",
    "## This notebook performs the following task(s):\n",
    "> - #### Reads in realtime, tabular data for a single buoy NDBC using pandas DataFrames. \n",
    "> - #### Creates a single pandas DataFrame with all the timeseries data for an individual buoy.\n",
    "> - #### Converts the pandas DataFrame into an xarray Dataset and exports the Dataset as a NetCDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "#### **Links to documentation for packages:**\n",
    "> - #### [requests](https://requests.readthedocs.io/en/latest/) | [numpy](https://numpy.org/doc/1.21/) | [xarray](https://docs.xarray.dev/en/stable/) | [pandas](https://pandas.pydata.org/pandas-docs/version/1.3.5/)\n",
    "> - #### Note #1: Documentation for packages linked above correspond to the most stable versions, which may not be the exact versions used when creating this notebook.\n",
    "> - #### Note #2: Comments are also included in the actual code cells. Commented links above certain pieces of code are provided to help show where some lines were copied from. It is possible that there may still be snippets of code here that were simply grabbed off the internet, from places like StackOverflow, without any atribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "#Import packages\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read realtime NDBC data for a single buoy into pandas DataFrames and append each yearly DataFrame into a list\n",
    "\n",
    "#### **Notes**\n",
    "> - #### It is pretty neat that pandas allows us to specify a URL with tabular data, which can be read directly into a DataFrame.\n",
    "> - #### For more information regarding NDBC realtime data see this [link](https://www.ndbc.noaa.gov/station_realtime.php?station=46053).\n",
    "> - #### Current buoy stations that we have downloaded data for are:\n",
    ">> - #### East Santa Barbara Buoy (Station 46053; [link to live data from NDBC](https://www.ndbc.noaa.gov/station_page.php?station=46053))\n",
    ">> - #### West Santa Barbara Buoy (Station 46054; [link to live data from NDBC](https://www.ndbc.noaa.gov/station_page.php?station=46054))\n",
    ">> - #### Harvest Buoy (Station 46218; [link to live data from NDBC](https://www.ndbc.noaa.gov/station_page.php?station=46218))\n",
    ">> - #### **Note:** The Harvest buoy is maintained by the Coastal Data Information Program [CDIP](https://cdip.ucsd.edu/). However, you can access a good chunk of its data from NDBC, which is the data repository that was used in this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "#Define buoy ID number\n",
    "#A few ID numbers around the Santa Barbara are are:\n",
    "#46218: Harvest buoy | 46054: West Santa Barbara buoy | 45053: East Santa Barbara buoy\n",
    "buoy_id        = 46054\n",
    "\n",
    "#Define URL to buoy data\n",
    "buoy_url = f'https://www.ndbc.noaa.gov/data/realtime2/{buoy_id}.txt'\n",
    "\n",
    "#Define parameters to make reading in buoy data easier\n",
    "\n",
    "#Column names for text file\n",
    "df_column_names = ['year', 'month', 'day', 'hour', 'minute', 'wind_dir_deg', 'wind_spd_ms', 'wind_gst_ms', 'wave_height_m', 'dom_wave_period_sec', 'average_wave_period_sec', 'mean_wave_dir_deg', 'pressure_hpa', 'air_temp_c', 'water_temp_c', 'dewpoint_c']\n",
    "\n",
    "#Date format string\n",
    "df_date_format  = f'%Y %m %d %H %M'\n",
    "\n",
    "#Which columns should we use to convert into our datetime index\n",
    "df_date_indexes = [0, 1, 2, 3, 4]\n",
    "\n",
    "#Which columns do we want to read in from the text file?\n",
    "df_use_cols = np.arange(0,15+1,1)\n",
    "\n",
    "#Whic rows do we want to skip when reading the file?\n",
    "skip_rows = 1\n",
    "\n",
    "#Define values that should be considered as NaNs\n",
    "nan_values = ['MM', 99.00, 999.0, 999, 9999.0]\n",
    "#-------------------------------------------------\n",
    "#Use a \"try-except\" workflow to deal with an HTTPError that may occur if data is not available for a specific buoy during a specific year\n",
    "#Thanks ChatGPT\n",
    "try:\n",
    "    #Use the requests package to examine the current buoy URL\n",
    "    response = requests.get(buoy_url)\n",
    "\n",
    "    #Check for HTTP errors\n",
    "    response.raise_for_status()  \n",
    "\n",
    "    #Read the data into a pandas DataFrame\n",
    "    #You will notice that there are a lot of custom options we specify when reading the buoy data using the \"read_csv\" function\n",
    "    #These were chosen based on ease of use for my personal python programming workflow\n",
    "    df = pd.read_csv(buoy_url, delim_whitespace=True, skiprows=skip_rows, header=0, na_values=nan_values, usecols=df_use_cols,\n",
    "                     names=df_column_names, parse_dates={'date':df_date_indexes}, date_format=df_date_format).set_index('date').sort_index(ascending=True)\n",
    "    \n",
    "#If there is an HTTPError, print it. \n",
    "#This will not stop the code from continuing to run for other years, which is what we want.\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(f\"HTTP Error: {errh}\")\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert pandas DataFrame to an xarray Dataset and export the final result as a NetCDF-4 file.\n",
    "\n",
    "#### **Notes**\n",
    "\n",
    "> - #### None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert this DataFrame into an Xarray DataSet\n",
    "ds = xr.Dataset.from_dataframe(df)\n",
    "\n",
    "#Export xarray Dataset to a NetCDF file\n",
    "ds.to_netcdf(path=f'ndbc_realtime_{buoy_id}.nc', mode='w', format='NETCDF4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (swex)",
   "language": "python",
   "name": "swex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
